# cluster maintenance
## Operating system upgrade
### what happens when a node is offline
- if pods are part of replicaset, they will be recreated on other nodes
- `eviction timeout` 
    - when pods are evicted from a node if node is offline for more than 5 minutes (default)
- for maintenance task for nodes
    - drain the node of pods
    - cordon the node (marked as unschedulable)
    - upgrade the node
    - uncordon the node
## K8s releases
- e.g. `v1.11.3` 
- `1` is the major version
- `11` is the minor version release every few months
- `3` is the patch version
- v1.0 is rleeased on july 2015
- etcd and coredns have their own release cycle
## Cluster upgrade process
- kube-apiserver is should have the highest version
- controller-manager and kube-schedulers can be x-1 version
- kubelet and kube-proxy can be at x-2 version
- kubectl can be x+1 higher or x-1 lower
### upgrade process
- k8s only support 3 minor releases behind
- e.g. when v1.12 is release, support is only up to v1.10
- should upgrade 1 minor version at a time, e.g. v1.10 -> v1.11
### upgrading process
1. upgrade master nodes
- control plane components briefly go down
    - apiserver
    - scheduler
    - controller-manager
- all workloads are not affected, only mgmt functions are down
2. upgrade worker nodes
- can upgrade all at once
- or 1 by 1 (drain and cordon)
3. provision new nodes with new versions 
- easier to do in cloud environments
- drain and cordon old nodes
#### using kubeadm
- `kubeadm upgrade plan` 
    - check if upgrade is possible
- kubelet needs to be manually upgraded.

## Maintenance
```bash
k drain <node> --ignore-daemonsets
k uncordon <node>
```
## Demo cluster upgrade
```bash
# Master node 
## drain 
k drain controlplane --ignore-daemonsets 
## upgrade kubeadm tool
apt update
apt-mark unhold kubeadm && \
apt-get update && apt-get install -y kubeadm=1.26.3-00 && \
apt-mark hold kubeadm
kubeadm upgrade apply v1.26.3
## update kubeadm
apt-mark unhold kubeadm && \
apt-get update && apt-get install -y kubeadm=1.26.3-00 && \
apt-mark hold kubeadm
# upgrade kubelet
apt-mark unhold kubelet kubectl && \
apt-get update && apt-get install -y kubelet=1.26.0-00 kubectl=1.26.0-00 && \
apt-mark hold kubelet kubectl
# restart kubelet
sudo systemctl daemon-reload
sudo systemctl restart kubelet
## for worker nodes
## ssh to the node 
ssh node01
# repeate same process
```

## Backup and restore methods
1. resource configuration
- store in git
- query the `kube-apiserver` via 
```bash
k get all --all-namespace -o yaml > all-deploy-services.yaml
```
2. etcd data
- backup etcd server itself
```bash
## backup
ETCDCTL_API=3 etcdctl snapshot save snapshot.db 
## check status
ETCDCTL_API=3 etcdctl snapshot status snapshot.db 
```
- restore etcd 
```bash
## stop etcd
service kube-apiserver stop
## restore - this creates a new etcd cluster with new data dir 
ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \
--data-dir /var/lib/etcd-from-backup
## update the etcd.service to point to new data dir 
--data-dir=/var/lib/etcd-from-backup
## reload and restart
systemctl daemon-reload
service etcd restart 
## restart apiserver
service kube-apiserver start
```
- remember to specify the certs when calling the etcdtl commands
```bash
ETCDCTL_API=3 etcdctl \
    snapshot save snapshot.db \
    --endpoints=https://127.0.0.1:2379 \
    --cacert=/etc/etcd/ca.crt \
    --cert=/etc/etcd/etcd-server.crt \
    --key=/etc/etcd/etcd-server.key
```

3. persistent volumes