# security

## Security Primitives
- controlling access to kube-apiserver
- Authentication
  - who can access?
- RBAC authorization
    - What can they do ?
- all communication is secured using TLS encryption
- all pods can access all other pods by default

## Authentication
- k8s does not manage user accounts natively
- relies on 3rd party services
- can manage service accounts natively
### Auth mechanisms
- for static password and token files, use a volume mount
1. static password file
- pass csv file to kube-apiserver with`basic-auth-file` flag
```csv
password,user,uid,groups
```
```yaml
apiVersion: v1
kind: Pod
metadata:
    name: kube-apiserver
spec:
    containers:
    - command:
        - kube-apiserver
        ...
        - --basic-auth-file=user-details.csv
```
- to authenticate, use the command
```bash
curl -v -k https://master-node:6443/api/v1/pods -u "user:password" 
```
2. static token file
`--token-auth-file` flag
```csv
token123,user,uid,groups
```
- to authenticate, use the command
```bash
curl -kv https://master-node:6443/api/v1/pods \
--header "Authorization: Bearer token123"
```
3. certificates
4. identity providers

## TLS introduction
- Transport Layer Security
- certs are used to guaranteed trust between 2 parties

## TLS in k8s
*.pem - server cert
*.key - private key
- all communication must be done via TLS
### server certs
1. kube-api 
- apiserver.crt
- apiserver.key
- the only client that talks to etcd server 
1b. kube-api to kubelet
- apiserver-kubelet-client.crt
- apiserver.kubelet-client.key
2. etcd
- etcdserver.crt
- etcdserver.key
3. kubelet
- kubelet.crt
- kubelet.key
### clients
1. admin
- admin.crt
- admin.key
2. kube-scheduler
- scheduler.crt
- scheduler.key
3. kube-controller-manager
- controller-manager.crt
- controller-manager.key
4. kube-proxy
- kube-proxy.crt
- kube-proxy.key
### Certificate authority 
- must have at least 1 CA for the cluster
- can have 1 CA for etcd and 1 for others
- ca.cert
- ca.key
### Certificate creation
```bash
# 1. create private key
openssl genrsa -out ca.key 2048
# 2. create certificate signing request
openssl req -new -key ca.key -subj "/CN=KUBERNETES-CA" -out ca.csr
# 3. create self signed certificate 
openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt
```
### Client certificate
```bash
# 1. create private key
openssl genrsa -out admin.key 2048
# 2. create certificate signing request
openssl req -new -key admin.key -subj "/CN=kube-admin" -out admin.csr
# 2.b can include permissions in the certificate as well 
openssl req -new -key admin.key \
-subj "/CN=kube-admin/O=system:masters" -out admin.csr
# 3. openssl x509 -req -in admin.csr -CA ca.crt -CAkey ca.key -out admin.crt
openssl x509 -req -in admin.csr -CA ca.crt -CAkey ca.key -out admin.crt
```
### other core components
- `SYSTEM:KUBE-SCHEDULER`
- `SYSTEM:KUBE-CONTROLLER-MANAGER`
- `SYSTEM:KUBE-PROXY`
### Using via curl
```bash
curl https://kube-apiserver:6443/api/v1/pods \
--key admin.key --cert admin.crt --cacert ca.crt
```
### using via kube-config.yaml
```yaml
apiVersion: v1
clusters:
- cluster:
    certificate-authority: ca.crt
    server: https://kube-apiserver.:6443
  name: kubernetes
kind: Config
...
```
### etcd server
- generate additional peer certs for distributed setup
### kube-api server
- all components talk to kube-api server
- some call it 
    - kubernetes 
    - kubernetes.default
    - kubernetes.default.svc
    - kubernetes.default.svc.cluster.local
    - <IP_ADDRESS>
- specify Subject alternate names
```cnf
...
[alt names]
DNS.1 = kubernetes
DNS.2 = kubernetes.default
DNS.3 = kubernetes.default.svc
DNS.4 = kubernetes.default.svc.cluster.local
IP.1 = <IP_ADDRESS>
...
```
### kubelet 
- https API server that runs on each node (captain)
- talks to kube-api server
- these certs are named after their nodes e.g node01, node02 etc
- `system:node:node01` is used as the CN 

### View certificates 
1. The hard way 
- generate certs manually via openssl
2. kubeadm
- takes care of everything
### checking logs for certs
```bash
journalctl -fu etcd.service 

kubectl logs etcd-master

# 1 level down 
docker ps -a | grep etcd
```
### Cert Signing process
1. create `CertificateSigningRequest` object
- must be in base64
```yaml
apiVersion: certificates.k8s.io/v1beta1
kind: CertificateSigningRequest
metadata:
    name: foo
spec:
    groups:
    - system:authenticated
    usages:
    - digital signature
    - key encipherment
    - server auth
    request: 
        <base64 encoded CSR>
```
2. review requests
```bash
k get csr
```
3. approve request
```yaml
k certificate approve jane
```
### Cert related operations
- carried out by the `Controller manager`
- controllers
1. csr-approving 
2. csr-signing

### Lab
```yaml
apiVersion: certificates.k8s.io/v1beta1
kind: CertificateSigningRequest
metadata:
    name: akshay
spec:
    groups:
    - system:authenticated
    signerName: kubernetes.io/kube-apiserver-client
    usages:
    - client auth
    request: <base64>
```
```bash
# 1. convert csr to base64
cat akshay.csr |base64 -w 0
# 2. create csr object
kubectl apply -f csr.yaml
# 3. approve csr
k certificate approve akshay
# 4. delete csr
k delete csr/akshay
```

## Kube config
- manually calling the endpoing is not practical
```bash
curl https://my-endpoint:6443/api/v1/pods \
--key admin.key \
--cert admin.crt \
--cacert ca.crt
# via k command
k get pods \
--server my-cluster:6443 \
--client-key admin.key \
--client-certificate admin.crt \
--certificate-authority ca.crt
```
- hence these are kept in `$HOME/.kube/config` file location
- specific format is used 
1. clusters
- dev, prod, etc
2. users 
- admin, dev, prod
3. contexts
- marries clusters and users
- e.g. grants admin user to production cluster
### kube config file
```yaml
apiVersion: v1
kind: Config
clusters:
- name: my-kube-playground
  cluster:
    certificate-authority: ca.crt
    server: https://my-kube-playground:6443
contexts:
- name: my-kube-admin@my-kube-playground
  context:
    user: my-kube-admin
    cluster: my-kube-playground
users:
- name: my-kube-admin
  user:
    client-certificate: admin.crt
    client-key: admin.key
```
- alternatively, can use the base64 data 
```yaml
apiVersion: v1
kind: Config
...
users:
- name: my-kube-admin
  user:
    client-certificate-data: <base64>
    client-key-data: <base64>
```
- commands for kube config
```bash
k config view
# tagerted view 
k config view --kubeconfig=my-config
# get contexts
k config get-contexts
# get current context
k config current-context
# set contexts 
k config use-context <context>
# get clusters
k config get-clusters
# set namespaces
k config set-context -current -namespace=dev
```
## API Groups
```bash
# get api version
curl https://kube-master:6443/version
```
1. core group
- `/api`
-- v1
--- namespaces, pods, bindings, secrets etc
2. named groups
- `/apis`
- apps, networking, auth, storage, certificates etc
- new features will fall under named groups
### start a proxy 
```bash
# uses certs from kubeconfig
kubectl proxy
# then access the api via proxy
curl http://localhost:8001 -k 
```
### kube proxy != kubectl proxy
- kubectl proxy is a http service to access the kube-api server
## Authorization
- what can they do
### types of auth
1. node authorizer
- authorizes kubelet nodes
2. Attribute based access control (ABAC)
- based on attributes of the request
- difficult to manage
3. Role based access control (RBAC)
- based on roles
- easier to manage
- e.g. create a developer role and associate users to the role
4. webhook
- using 3rd party tools like Open Policy Agent
5. AlwaysAllow
6. AlwaysDeny
### Authorization modes
- set via `--authorization-mode` flag on kube-api server
- set to `AlwaysAllow` by default
- can set multiple modes 
```bash
# follows in sequence of defined modes
--authorization-modes=Node,RBAC,Webhook
```
### RBAC
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: developer
rules:
- apiGroups: [""] # leave blank for core groups 
  resources: ["pods"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: [""]
  resources: ["ConfigMap"]
  verbs: ["create", "update", "patch"]
  resourceNames: ["dev","stg"] # restrict to resource name itself
```
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: developer-binding
subjects:
- kind: User
  name: developer1
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: developer
  apiGroup: rbac.authorization.k8s.io
```
```bash
# create the role based on the above yaml
k create -f developer-role.yaml
# link the role to a user
k create -f devuser-role-binding.yaml 
# view roles
k get roles
# get rolebindings
k get rolebindings
# describe role
k describe role developer
# decribe role bindings
k describe rolebindings devuser-role-binding
# check my user
k auth can-i create deployments
# impersonate other users
k auth can-i create pods --as dev-user --namespace test
```

## Cluster Roles and Cluster Rolebindings
- are namespaced

## Namespaces vs Cluster scoped
- resources can either be
  - namespaced
  - cluster scoped
## Cluster roles
- for cluster role resources
  - nodes
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-administrator
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list"]
```
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-admin-role-binding
subjects:
- kind: User
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: cluster-administrator
```
## accounts
- user accounts
- service accounts
### service accounts
```bash
# create sa
k create sa my-service-account
# get sa 
k get sa my-service-account -o yaml
# describe sa
k describe sa my-service-account
``` 
- tokens are generated for service accounts and stored in a secret object
- secret object is then mounted to the service account
- this token can be used as bearer token to authenticate to the kube-api server
### grant k8s apps to service account
- whenever a pod is created, the default service account and token is mounted as volume mount
- default sa only can call kube-api server
- cannot edit SA of a running pod
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-pod
      image: my-pod
  automountServiceAccounToken: false # disable mount of sa
```
- since v1.22, token request API is used instead
  - defined lifetime
  - audience
- since v1.24
  - need to run
```bash
k create sa my-service-account
k create token my-service-account
```
- defaults with 1 hour expiry
```bash
# update sa for a deployment
k set sa deploy/web-dashboard dashboard-sa
```

## images
- docker.io/library/nginx
- <registry>/<user/account>/<image_repository>
### authentication to private registries
- via secret object with registry credentials
```bash
k create secret docker-registry regcred \
--docker-server=<registry> \
--docker-username=<user> \
--docker-password=<password> \
--docker-email=<email>
```
- use the secret in a pod spec
```yaml
apiVersion: v1
kind: Pod
metadata: 
  name: my-pod
spec:
  containers:
    - name: my-pod
      image: private-registry.io/apps/internal-app:latest
    imagePullSecrets:
    - name: regcred
```